{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. <a id='intro'>[Pandas](https://www.freecodecamp.org/news/how-to-analyze-data-with-python-pandas/)</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite NumPy powerful, it has critical drawbacks:\n",
    "\n",
    "- It lacks support for column names, requiring us to formulate inquiries in the context of multi-dimensional array operations.\n",
    "- It permits only a single data type per ndarray, leading to complications in managing mixed numeric and string data.\n",
    "- Despite the existence of numerous low-level methods, certain common analysis patterns do not have pre-existing methods.\n",
    "\n",
    "Fortunately, Pandas (from panel data) come to the rescue!\n",
    "\n",
    "*Based on Dataquest course \"Data Ana√±yst in Python\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <a href='#def'>3.1. Definition</a>  \n",
    "- <a href='#series'>3.2. Pandas Series</a>\n",
    "     - <a href='#3.2.1'>3.2.1. From `lists` to `Series`</a>\n",
    "     - <a href='#3.2.2'> 3.2.2. From `NumPy array` to `Series`</a>\n",
    "     - <a href='#3.2.3'> 3.2.3. From `Dictionary` to `Series`</a>\n",
    "     - <a href='#3.2.4'> 3.2.4. `Series` vs `NumPy`</a>\n",
    "     - <a href='#3.2.5'> 3.2.5 Indexing</a></a>\n",
    "- <a href='#3.3'>3.3 DataFrame</a>\n",
    "     - <a href='#3.3.1'>3.3.1 DataFrame Generation</a>\n",
    "     - <a href='#3.3.2'>3.3.2 Indexing</a>\n",
    "     - <a href='#3.3.3'>3.3.3 General Methods</a>\n",
    "     - <a href='#3.3.4'>3.3.4 Importing Data</a>\n",
    "     - <a href='#3.3.5'>3.3.5 Filtering data</a> \n",
    "     - <a href='#3.3.6'>3.3.6 Dealing with nulls</a>  \n",
    "     - <a href='#3.3.7'>3.3.7 Duplicates</a>  \n",
    "     - <a href='#3.3.8'>3.3.8 Groupby</a>  \n",
    "     - <a href='#3.3.9'>3.3.9 Reshape</a>  \n",
    "     - <a href='#3.3.10'>3.3.10 Merge</a>  \n",
    "     \n",
    "- <a href='#3.4'>3.4 References</a>  \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. <a id='def'>Definition</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a Python library used for working with data sets. This is the \"must-learn\" library for Data I/O, cleaning, transforming and aggregation. It is an external library so we need to import it in your applications by adding the `import` keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the `Pandas` package can be referred to as `pd` instead of pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. <a id='series'>[Pandas Series](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html)</a>\n",
    "\n",
    "The first pandas data strucuture is a Series. A Series is a one-dimensional array that can hold any datatype, similar to a ndarray. However, a Series has a **index** that gives a a label to each entry. An index generally is used to label the data.\n",
    "Typically a Series contains information about **one feature** of the data. <br>\n",
    "\n",
    "A `Pandas Series` is a one-dimensional array of indexed data. It can be created from a list or array as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. <a id='3.2.1'>From `lists` to `Series`<a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = [ 0.25, 0.5, 0.75, 1.0 ]\n",
    "list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series( list_1 )\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. <a id='3.2.2'> From `NumPy array` to `Series` <a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_1 = np.array( [ 10, 20, 1, 2, \n",
    "                    3, 4, 5, 6, 7 ] )\n",
    "vector_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series1 = pd.Series( vector_1 )\n",
    "series1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_2  = np.array( [ 10, 20, 7 ] ) \n",
    "vector_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series1 = pd.Series( vector_2 , index = [\"Brisa\", \"Alex\", \"Valeria\"] )\n",
    "series1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3.  <a id='3.2.3'> From `Dictionary` to `Series` </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_dict = { 'California' : 38332521.0,\n",
    "                    'Texas'      : 26448193,\n",
    "                    'New York'   : 19651127,\n",
    "                    'Florida'    : 19552860,\n",
    "                    'Illinois'   : 12882135 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.Series( population_dict, name=\"States_Pop\")\n",
    "population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see in the output, the `Series` wraps both a sequence of values and a sequence of indices, which we can access with the `values` and `index` attributes. The values are simply a familiar NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4.  <a id='3.2.4'> `Series` vs `NumPy`</a>\n",
    "\n",
    "The essential difference is the presence of the index: while the `Numpy Array` has an implicitly defined integer index used to access the values, the `Pandas Series` has an explicitly defined index associated with the values. <br>\n",
    "\n",
    "The `index` do not need to be an integer. we can use `strings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claudia = np.arange(5, 21, 2)\n",
    "claudia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math = pd.Series( np.arange(5.,21.,3.) , ['joyce','jeremy','ivan','marcy','daniel','franclin'])\n",
    "math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = np.arange(5 , 15 ,3.)\n",
    "index_info =  ['joyce','jeremy','ivan','marcy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math_2 = pd.Series(  info , index_info, dtype = int,  name = \"Daniel\")\n",
    "math_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excersice: <br>\n",
    "Get the `values` and `index` from `math` `Series`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.5.  <a id='3.2.5'> Indexing</a>\n",
    "\n",
    "\n",
    "Indexing in pandas means simply selecting particular rows and columns of data from a DataFrame. Indexing could mean selecting all the rows and some of the columns, some of the rows and all of the columns, or some of each of the rows and columns. Indexing can also be known as Subset Selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( data )\n",
    "print( population )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[ 0:2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[ 3:4 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population[ \"New York\":\"Illinois\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( population[ 'California':'Texas' ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Method \t| Definition \t|\n",
    "| --- \t| --- \t|\n",
    "| loc() \t| Gets rows (and/or columns) with particular labels.<br> Accept `Boolean` for indexing. |\n",
    "| iloc() \t| gets rows (and/or columns) at integer locations. <br> Do not accept `Boolean` for indexing.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the value of New York."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "population.loc[ \"New York\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_2 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population.iloc[ [True, True, False, False, True] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( population.loc[ \"New York\" ] == population.iloc[ 2 ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replicate this excersice for `data` Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3.  <a id='3.3'> [DataFrame](https://www.w3schools.com/python/pandas/pandas_dataframes.asp)</a>\n",
    "\n",
    "\n",
    "A DataFrame is a collection of multiple Series. It can be thought of as a 2-dimensional array, where each row is a separate datapoint and each column is a feature of the data. The rows are labeled with an index(as in a Series) and the columns are lebeled in the attribute columns.<br>\n",
    "There are many different ways to initialize a DataFrame. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1. <a id='3.3.1'> DataFrame Generation</a>\n",
    "#### From `lists` and `dict` to `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grades\n",
    "students = [ \"Alejandro\", \"Pedro\", \"Ramiro\", \"Axel\", \"Juan\" ]\n",
    "math     = [ 15, 16, 10, 12, 13 ]\n",
    "english  = [ 13, 9, 16, 14, 17 ]\n",
    "art      = [ 12, 16, 15, 19, 10 ]\n",
    "\n",
    "# Dictionary\n",
    "grades_A = { 'Students':students, 'Math':math, 'English':english, 'Art':art }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradesA1 = pd.DataFrame( grades_A )\n",
    "gradesA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_A[\"dataframe_stephy\"] = gradesA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_A.pop(\"dataframe_stephy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradesA1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From `lists` and `NumPy` to `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = [ 1, 2, 3 ]\n",
    "list_2 = [ 4, 5, 6 ]\n",
    "list_3 = [ 7, 8, 9 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.array([list_1 ,list_2 ,list_3 ] )\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [ 'a', 'b', 'c' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.DataFrame( values, columns = col_names, index = [\"cesar\", \"joaquin\", \"jennifer\"] )\n",
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2. <a id='3.3.2'> Indexing</a>\n",
    "\n",
    "We can use the same methods as `Series`: `iloc` and `loc`. We can select columns and rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grades\n",
    "students = [ \"Gissela\", \"Daniel\", \"Andres\", \"Sandra\", \"Rosalyn\" ]\n",
    "math     = [ 16, 14, 17, 17, 17 ]\n",
    "english  = [ 16, 17, 19, 18, 15 ]\n",
    "art      = [ 11, 17, 13, 14, 17 ]\n",
    "\n",
    "# Dictionary\n",
    "diplomado = {'Students':students, 'Math':math, 'English':english, 'Art':art}\n",
    "gradesA1 = pd.DataFrame( diplomado )\n",
    "gradesA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradesA1.loc[ 0:0 , : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradesA1.loc[ : , [\"Students\", \"Art\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradesA1.loc[ 0:3 , [\"Students\" , \"Math\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradesA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iloc\n",
    "gradesA1.iloc[ 0:2 , 0:2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradesA1.iloc[ 0:2, 0:3 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradesA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradesA1.iloc[ [0, 2, 4] , : ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3. <a id='3.3.3'> General Methods</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Method|Description|\n",
    "|------|-----------|\n",
    "|columns()|Get the name of the columns.|\n",
    "|sort_values()|Sort by the values along either axis.|\n",
    "|sort_index()|Sort by the index.|\n",
    "|head()|Show the first N observations.|\n",
    "|drop( )| Remove the entries  <br>  with the specified label or labels|\n",
    "|append( )| Concatenate two or more Series.|\n",
    "|drop_duplicates( )| Remove duplicate values|\n",
    "|dropna( ) |Drop null entries|\n",
    "|fillna( ) |Replace null entries <br> with a specified value or strategy|\n",
    "|reset_index( )| Index as column.|\n",
    "|sample( ) |Draw a random entry|\n",
    "|shift( ) |Shift the index|\n",
    "|unique( ) |Return unique values|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "\n",
    "df = pd.DataFrame(data=[22,22,3],\n",
    "                  index=[dt(2023, 11, 10, 0), dt(2023, 11, 10, 13), dt(2023, 11, 13, 5)],\n",
    "                  columns=['foo'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.sort_values(by='foo')\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='foo', inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deps = {\n",
    "        'dep' : ['Lima', 'Piura', 'Tumbes', 'Cuzco', 'Ica', 'Puno'],\n",
    "        'year': [ 2000, 2001, 2002, 2001, 2002, 2003 ],\n",
    "        'pop' : [ 1.5, 1.7, 3.6, 2.4, 2.9, 3.2 ] \n",
    "        }\n",
    "dep1 = pd.DataFrame( deps )\n",
    "dep1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep1.sort_values( [\"year\"] , ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep1.sort_values( [ \"year\", \"pop\" ] , ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep1.sort_values( [ \"year\", \"pop\" ] , ascending = True, inplace = True)\n",
    "dep1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back to the original\n",
    "dep1.sort_index( inplace = True )\n",
    "dep1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradesA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gradesA1[ 'Math' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradesA1[ 'Math' ]+50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operations with DataFrame, new column\n",
    "gradesA1[ \"avg\" ] = ( gradesA1[ 'Math' ] + gradesA1[ 'English' ] + gradesA1[ 'Art' ] ) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradesA1[\"avg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradesA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Math & English\n",
    "gradesA1.iloc[:, 2:4].mean( axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Math adn Art\n",
    "gradesA1.iloc[:, [1, 3]].mean( axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# head\n",
    "gradesA1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradesA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradesA1_2 = gradesA1.drop( [\"avg\", \"English\"] , axis = 1 )\n",
    "gradesA1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new data gradesA2\n",
    "students = [ \"Rebeca\", \"Xavi\", \"Cristiano\", \"Ronaldo\", \"Leo\" ]\n",
    "math     = [ 15, 18, 14, 7, 10 ]\n",
    "english  = [ 18, 9, 11, 12, 20 ]\n",
    "art      = [ 10, 16, 20, 19, 5 ]\n",
    "\n",
    "# Dictionary\n",
    "grades_A2 = {'Students':students, 'Math':math, 'English':english, 'Art':art}\n",
    "gradesA2 = pd.DataFrame( grades_A2 )\n",
    "print(gradesA2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gradesA1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradesA1  = gradesA1.drop( [ 'avg' ], axis = 1 )\n",
    "gradesA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_total = pd.concat([gradesA1,gradesA2], ignore_index = True)\n",
    "grades_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_total =  pd.concat([gradesA1,gradesA2])\n",
    "grades_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.DataFrame({\n",
    "            'brands'    : [ 'hyundai', 'hyundai', 'kia', 'kia', 'kia' ] ,\n",
    "            'model'     : [ 'sedan', 'sedan', 'sedan', 'truck', 'truck' ] ,\n",
    "            'passengers': [ 4, 4, 5, 6, 8 ]\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates\n",
    "cars_subset1 = cars.drop_duplicates(subset = [ 'brands' ])\n",
    "cars_subset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates\n",
    "cars_subset2 = cars.drop_duplicates( subset = [\"brands\"] , keep = \"last\")\n",
    "cars_subset2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradesA1_1 = gradesA1.drop( ['Art'], axis = 1 )\n",
    "gradesA1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_total  = pd.concat([gradesA1_1, gradesA2] ,  ignore_index = True).copy()\n",
    "grades_total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna\n",
    "grades_total.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna\n",
    "grades_total_NA = grades_total.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_total_NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_total.fillna( \"5\" )\n",
    "grades_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillna\n",
    "grades_total_fill_na = grades_total.fillna( \"5\" )\n",
    "grades_total_fill_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grades_total.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_total.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_total.reset_index( drop = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_total.sample( n = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_total.sample( frac = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique\n",
    "cars['brands'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4. <a id='3.3.4'> Importing Data</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Method|Description|\n",
    "|------|-----------|\n",
    "|read_excel( )|Read a excel file and convert to a DataFrame.|\n",
    "|to_csv( )| Write the index and entries to a CSV file|\n",
    "|read_csv( )| Read a csv and convert into a DataFrame|\n",
    "|to_json( )| Convert the object to a JSON string|\n",
    "|to_pickle( )| Serialize the object and store it in an external file|\n",
    "|to_sql( )| Write the object data to an open SQL database|\n",
    "|read_html( )| Read a table in an html page and convert to a DataFrame|\n",
    "|read_spss( )| Read a spss file and convert to a DataFrame.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ENAPRES DATA](http://proyecto.inei.gob.pe/enapres/)\n",
    "\n",
    "The National Survey of Budgetary Programs - ENAPRES, has been running since 2010 in the urban and rural areas of the 24 Departments and the Constitutional Province of Callao, as part of the research carried out by the National Institute of Statistics and Informatics (INEI) in coordination with the Ministry of Economy and Finance (MEF) and the different ministries and agencies of the public sector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read sav data using pyreadstat\n",
    "enapres2022, meta =pyreadstat.read_sav(r\"785-Modulo1727/CAP_100_URBANO_RURAL_3.sav\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(enapres2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enapres2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read sav data using pyreadstat\n",
    "enapres2022, meta =pyreadstat.read_sav(r\"785-Modulo1727/CAP_100_URBANO_RURAL_3.sav\" , apply_value_formats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "enapres2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.5. <a id='3.3.5'>Filtering data</a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select observations\n",
    "# when we create a sample from our data, copy the object.\n",
    "df_urban_main = enapres2022.loc[ enapres2022.AREA == 'URBANO', : ]\n",
    "df_urban_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urban = df_urban_main.loc[ df_urban_main.RESFIN == 'Completa', : ]\n",
    "df_urban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = enapres2022.loc[ (enapres2022.AREA == 'URBANO') &  (enapres2022.RESFIN == 'Completa') , : ]\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urban.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns with regex\n",
    "# All the columns that start with P172\n",
    "df_urban.filter( regex = \"P172*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all columns that have an X\n",
    "df_urban.filter( like = \"P172\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Name': ['John', 'Doe', 'Alice', 'Bob', 'Chris'],\n",
    "    'Age': [25, 30, 22, 28, 35],\n",
    "    'Salary': [50000, 60000, None, 75000, 90000],\n",
    "    'Experience': [2, 5, 1, None, 10]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_nan_count = df.isna().sum()\n",
    "\n",
    "print(salary_nan_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.6. <a id='3.3.6'>Dealing with nulls</a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop columns that at least 30% values are null to simplify our Exploratory Data Analysis (EDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_sum = df_urban.isna().sum()\n",
    "null_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urban.columns[ null_sum < len( df_urban ) * 0.2 ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urban.drop(columns = df_urban.columns[null_sum > len( df_urban ) * 0.2 ], inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urban"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cheack ID in pandas\n",
    "( df_urban['PER'].astype(str)+ \"_\" + \n",
    " df_urban['MES'].astype(str)+ \"_\" + \n",
    " df_urban['CCDD'].astype(str) + \"_\" + \n",
    " df_urban['CCPP'].astype(str) + \"_\" + \n",
    " df_urban['CCDI'].astype(str) + \"_\" + \n",
    " df_urban['CONGLOMERADO'].astype(str) + \"_\" + \n",
    " df_urban['NSELV'].astype(str) + \"_\" +\n",
    " df_urban['VIVIENDA'].astype(str) + \"_\" + \n",
    " df_urban['HOGAR'].astype(int).astype(str) \n",
    ").is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.7. <a id='3.3.7'>[Duplicates](https://thispointer.com/pandas-find-duplicate-rows-in-a-dataframe-based-on-all-or-selected-columns-using-dataframe-duplicated-in-python/)</a>  \n",
    "\n",
    "See duplicatedes in rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urban[ df_urban.loc[:, ['CCDD' ,'CCPP' , 'CCDI' ,'CONGLOMERADO' , 'NSELV', 'VIVIENDA', 'HOGAR']].duplicated( keep=False) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop the last duplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urban_no_dpl = df_urban[ ~df_urban.loc[:, ['CCDD' ,'CCPP' , 'CCDI' ,'CONGLOMERADO' , 'NSELV', 'VIVIENDA', 'HOGAR']].duplicated() ].copy()\n",
    "df_urban_no_dpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urban_no_dpl.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urban_no_dpl.ESTRATO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.8. <a id='3.3.8'>Groupby</a>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from yes to 1 and 0 to no\n",
    "df_urban_no_dpl['P172D'] = df_urban_no_dpl['P172D'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_urban_no_dpl.P172D.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_urban_no_dpl.groupby( [ 'CCDD' ,'P172D' ] )[['P172D']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urban_no_dpl.groupby( [ 'CCDD' ] )[['P172D']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urban_no_dpl.groupby( [ 'CCDD' ], as_index = False )[['P172D']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Agg](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html)\n",
    "Aggregate using one or more operations over the specified axis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urban_no_dpl['P172D'] = df_urban_no_dpl['P172D'].astype( float )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urban_no_dpl.groupby( [ 'CCDD' ,'CCPP' , 'CCDI' ], as_index = False ).agg( { \"P172D\": \"mean\" } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_rec = df_urban_no_dpl.groupby( [ 'CCDD' ,'CCPP' , 'CCDI' ] , \n",
    "                                as_index = False \n",
    "                               ).agg( \n",
    "                                    recycle_median = ( 'P172D', np.median ), \n",
    "                                    recycle_mean = ( 'P172D', np.mean ) \n",
    "                                )\n",
    "df3_rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.9. <a id='3.3.9'>Reshape</a>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  From Wide to Long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_rec_stack = df3_rec.set_index(  [ 'CCDD' ,'CCPP' , 'CCDI' ]  ).stack().reset_index().rename( {\"level_3\" : \"STATS\", \n",
    "                                                                                0 : \"VALUES\" }, axis = 1 )\n",
    "df3_rec_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_rec_melt = df3_rec.melt( \n",
    "                    id_vars = [ 'CCDD' ,'CCPP' , 'CCDI' ] ,\n",
    "                    var_name = 'STATS', \n",
    "                    value_name = 'VALUES'\n",
    "                 )\n",
    "df3_rec_melt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From Long to Wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_rec_stack.set_index(  [ 'CCDD' ,'CCPP' , 'CCDI' , \"STATS\" ]  ).unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df4 = df3_rec_stack.set_index(  [ 'CCDD' ,'CCPP' , 'CCDI' , \"STATS\" ]   ).unstack().rename_axis( [None, None], axis = 1 )\n",
    "\n",
    "\n",
    "df4.columns = df3_rec_stack.STATS.unique()\n",
    "\n",
    "df4.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_l_w = df3_rec_stack.pivot( index = [ 'CCDD' ,'CCPP' , 'CCDI' ], \n",
    "                         columns = 'STATS' ,\n",
    "                         values = 'VALUES' \n",
    "                        ).rename_axis( [None], axis = 1 ).reset_index()\n",
    "df_l_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.10. <a id='3.3.10'>[Merge](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html)</a>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urban_merge = df_urban_no_dpl.merge( df_l_w , on = [ 'CCDD' ,'CCPP' , 'CCDI' ] , how = \"left\" , validate = \"m:1\" ).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urban_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See all your DataFrames\n",
    "%whos DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. <a id='3.4'>References</a>  \n",
    "\n",
    "1. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.agg.html\n",
    "2. https://towardsdatascience.com/all-the-core-functions-of-python-pandas-you-need-to-know-d219cbd87636\n",
    "3. https://pandas.pydata.org/docs/reference/api/pandas.melt.html#pandas.melt\n",
    "4. https://stackoverflow.com/questions/47152691/how-can-i-pivot-a-dataframe\n",
    "5. https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.pivot.html\n",
    "6. https://stackoverflow.com/questions/11346283/renaming-column-names-in-pandas\n",
    "7. https://thispointer.com/pandas-find-duplicate-rows-in-a-dataframe-based-on-all-or-selected-columns-using-dataframe-duplicated-in-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
